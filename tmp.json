{
    "replace": "# ============================================================================\n# VAE Decoder",
    "path": "examples/flux-klein-4b.py",
    "content": "from tensor_graphs.ops.registry import register_reference_factory\nfrom tensor_graphs.ops.atomic_types import OpType\n\n\n# ============================================================================\n# VAE Self Attention Decomposition\n# ============================================================================\n\n\ndef vae_self_attn_decomposition(inputs, attrs=None):\n    \"\"\"\n    Decomposition for VAE Self Attention:\n    Input: Q, K, V [B, C, H, W]\n    Output: Out [B, C, H, W]\n    \"\"\"\n    q, k, v = inputs\n\n    # Assume static shapes for now as inferred by propagation\n    if q.shape is None:\n        raise ValueError(\"VAESelfAttn decomposition requires inferred shapes\")\n\n    B, C, H, W = q.shape\n    L = H * W\n    scale_val = C**-0.5\n\n    # 1. Flatten spatial dimensions: [B, C, H, W] -> [B, C, L]\n    # We use Permute [0, 2, 3, 1] -> [B, H, W, C] then Reshape [B, L, C]\n\n    perm_hwc = TensorNode(OpType.PERMUTE, q.dtype, [q], attrs={\"dims\": [0, 2, 3, 1]})\n\n    shape_blc = TensorNode(\n        OpType.CONSTANT,\n        DType.INT32,\n        [],\n        attrs={\"value\": np.array([B, L, C], dtype=np.int32)},\n    )\n\n    q_flat = TensorNode(OpType.RESHAPE, q.dtype, [perm_hwc, shape_blc])\n\n    # Similarly for K and V\n    perm_k = TensorNode(OpType.PERMUTE, k.dtype, [k], attrs={\"dims\": [0, 2, 3, 1]})\n    k_flat = TensorNode(OpType.RESHAPE, k.dtype, [perm_k, shape_blc])\n\n    perm_v = TensorNode(OpType.PERMUTE, v.dtype, [v], attrs={\"dims\": [0, 2, 3, 1]})\n    v_flat = TensorNode(OpType.RESHAPE, v.dtype, [perm_v, shape_blc])\n\n    # 2. Attention\n    # Q: [B, L, C], K: [B, L, C]\n    # Scores = Q @ K.T -> [B, L, C] @ [B, C, L] -> [B, L, L]\n    k_t = TensorNode(OpType.PERMUTE, k.dtype, [k_flat], attrs={\"dims\": [0, 2, 1]})\n    scores = TensorNode(OpType.DOT, q.dtype, [q_flat, k_t])\n\n    # Scale\n    scale_node = TensorNode(\n        OpType.CONSTANT, q.dtype, [], attrs={\"value\": float(scale_val)}\n    )\n    scores_scaled = TensorNode(OpType.MUL, q.dtype, [scores, scale_node])\n\n    # Softmax\n    probs = TensorNode(\"Softmax\", q.dtype, [scores_scaled], attrs={\"axis\": -1})\n\n    # Out = Probs @ V -> [B, L, L] @ [B, L, C] -> [B, L, C]\n    attn_out_flat = TensorNode(OpType.DOT, q.dtype, [probs, v_flat])\n\n    # 3. Reshape back\n    # [B, L, C] -> [B, H, W, C] -> [B, C, H, W]\n    shape_bhwc = TensorNode(\n        OpType.CONSTANT,\n        DType.INT32,\n        [],\n        attrs={\"value\": np.array([B, H, W, C], dtype=np.int32)},\n    )\n    out_hwc = TensorNode(OpType.RESHAPE, q.dtype, [attn_out_flat, shape_bhwc])\n\n    out_nchw = TensorNode(\n        OpType.PERMUTE, q.dtype, [out_hwc], attrs={\"dims\": [0, 3, 1, 2]}\n    )\n\n    return out_nchw\n\n\nregister_reference_factory(\"VAESelfAttn\", vae_self_attn_decomposition)\n\n\n# ============================================================================\n# VAE Decoder\n"
}